{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53019d5-8a9d-4261-9bf8-5aaa1c2ba21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\mldl\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\mldl\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\mldl\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\mldl\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\mldl\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37375571-4571-4806-9d5b-82fdce3acb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\")\n",
    "text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7742c3a5-0c3d-46b3-98fb-900e02868f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                       Language is never, ever, ever, random\\n\\n                                                               ADAM KILGARRIFF\\n\\n\\n\\n\\nAbstract\\nLanguage users never choose words randomly, and language is essentially\\nnon-random. Statistical hypothesis testing uses a null hypothesis, which\\nposits randomness. Hence, when we look at linguistic phenomena in cor-\\npora, the null hypothesis will never be true. Moreover, where there is enough\\ndata, we shall (almost) always be able to establish '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62056a3f-0a53-44e5-8585-3026098f1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e7345f-7dd1-4eda-b481-92bcaebb1b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                       Language is never, ever, ever, random\\n\\n                                                               ADAM KILGARRIFF\\n\\n\\n\\n\\nAbstract\\nLanguage users never choose words randomly, and language is essentially\\nnon-random.',\n",
       " 'Statistical hypothesis testing uses a null hypothesis, which\\nposits randomness.',\n",
       " 'Hence, when we look at linguistic phenomena in cor-\\npora, the null hypothesis will never be true.',\n",
       " 'Moreover, where there is enough\\ndata, we shall (almost) always be able to establish that it is not true.',\n",
       " 'In\\ncorpus studies, we frequently do have enough data, so the fact that a rela-\\ntion between two phenomena is demonstrably non-random, does not sup-\\nport the inference that it is not arbitrary.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "600d7740-41e6-4c56-9d43-ce0ed21e21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [list(map(str.lower, word_tokenize(sentence))) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4643a261-019f-429d-bc28-cf1eb15b6ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['language',\n",
       "  'is',\n",
       "  'never',\n",
       "  ',',\n",
       "  'ever',\n",
       "  ',',\n",
       "  'ever',\n",
       "  ',',\n",
       "  'random',\n",
       "  'adam',\n",
       "  'kilgarriff',\n",
       "  'abstract',\n",
       "  'language',\n",
       "  'users',\n",
       "  'never',\n",
       "  'choose',\n",
       "  'words',\n",
       "  'randomly',\n",
       "  ',',\n",
       "  'and',\n",
       "  'language',\n",
       "  'is',\n",
       "  'essentially',\n",
       "  'non-random',\n",
       "  '.'],\n",
       " ['statistical',\n",
       "  'hypothesis',\n",
       "  'testing',\n",
       "  'uses',\n",
       "  'a',\n",
       "  'null',\n",
       "  'hypothesis',\n",
       "  ',',\n",
       "  'which',\n",
       "  'posits',\n",
       "  'randomness',\n",
       "  '.'],\n",
       " ['hence',\n",
       "  ',',\n",
       "  'when',\n",
       "  'we',\n",
       "  'look',\n",
       "  'at',\n",
       "  'linguistic',\n",
       "  'phenomena',\n",
       "  'in',\n",
       "  'cor-',\n",
       "  'pora',\n",
       "  ',',\n",
       "  'the',\n",
       "  'null',\n",
       "  'hypothesis',\n",
       "  'will',\n",
       "  'never',\n",
       "  'be',\n",
       "  'true',\n",
       "  '.'],\n",
       " ['moreover',\n",
       "  ',',\n",
       "  'where',\n",
       "  'there',\n",
       "  'is',\n",
       "  'enough',\n",
       "  'data',\n",
       "  ',',\n",
       "  'we',\n",
       "  'shall',\n",
       "  '(',\n",
       "  'almost',\n",
       "  ')',\n",
       "  'always',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'establish',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'true',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'corpus',\n",
       "  'studies',\n",
       "  ',',\n",
       "  'we',\n",
       "  'frequently',\n",
       "  'do',\n",
       "  'have',\n",
       "  'enough',\n",
       "  'data',\n",
       "  ',',\n",
       "  'so',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'a',\n",
       "  'rela-',\n",
       "  'tion',\n",
       "  'between',\n",
       "  'two',\n",
       "  'phenomena',\n",
       "  'is',\n",
       "  'demonstrably',\n",
       "  'non-random',\n",
       "  ',',\n",
       "  'does',\n",
       "  'not',\n",
       "  'sup-',\n",
       "  'port',\n",
       "  'the',\n",
       "  'inference',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'arbitrary',\n",
       "  '.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8628c840-d206-4731-92e8-3822618b510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dde01ac-38ff-4bb2-a27f-f9e60634631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, padded_sentences = padded_everygram_pipeline(3, tokenized_text)  # train_data - everygram(max_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d19c319-dd4e-4070-8b8b-3e2a6e2c9d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>',),\n",
       " ('<s>', '<s>'),\n",
       " ('<s>', '<s>', 'language'),\n",
       " ('<s>',),\n",
       " ('<s>', 'language'),\n",
       " ('<s>', 'language', 'is'),\n",
       " ('language',),\n",
       " ('language', 'is'),\n",
       " ('language', 'is', 'never'),\n",
       " ('is',),\n",
       " ('is', 'never'),\n",
       " ('is', 'never', ','),\n",
       " ('never',),\n",
       " ('never', ','),\n",
       " ('never', ',', 'ever'),\n",
       " (',',),\n",
       " (',', 'ever'),\n",
       " (',', 'ever', ','),\n",
       " ('ever',),\n",
       " ('ever', ','),\n",
       " ('ever', ',', 'ever'),\n",
       " (',',),\n",
       " (',', 'ever'),\n",
       " (',', 'ever', ','),\n",
       " ('ever',),\n",
       " ('ever', ','),\n",
       " ('ever', ',', 'random'),\n",
       " (',',),\n",
       " (',', 'random'),\n",
       " (',', 'random', 'adam'),\n",
       " ('random',),\n",
       " ('random', 'adam'),\n",
       " ('random', 'adam', 'kilgarriff'),\n",
       " ('adam',),\n",
       " ('adam', 'kilgarriff'),\n",
       " ('adam', 'kilgarriff', 'abstract'),\n",
       " ('kilgarriff',),\n",
       " ('kilgarriff', 'abstract'),\n",
       " ('kilgarriff', 'abstract', 'language'),\n",
       " ('abstract',),\n",
       " ('abstract', 'language'),\n",
       " ('abstract', 'language', 'users'),\n",
       " ('language',),\n",
       " ('language', 'users'),\n",
       " ('language', 'users', 'never'),\n",
       " ('users',),\n",
       " ('users', 'never'),\n",
       " ('users', 'never', 'choose'),\n",
       " ('never',),\n",
       " ('never', 'choose'),\n",
       " ('never', 'choose', 'words'),\n",
       " ('choose',),\n",
       " ('choose', 'words'),\n",
       " ('choose', 'words', 'randomly'),\n",
       " ('words',),\n",
       " ('words', 'randomly'),\n",
       " ('words', 'randomly', ','),\n",
       " ('randomly',),\n",
       " ('randomly', ','),\n",
       " ('randomly', ',', 'and'),\n",
       " (',',),\n",
       " (',', 'and'),\n",
       " (',', 'and', 'language'),\n",
       " ('and',),\n",
       " ('and', 'language'),\n",
       " ('and', 'language', 'is'),\n",
       " ('language',),\n",
       " ('language', 'is'),\n",
       " ('language', 'is', 'essentially'),\n",
       " ('is',),\n",
       " ('is', 'essentially'),\n",
       " ('is', 'essentially', 'non-random'),\n",
       " ('essentially',),\n",
       " ('essentially', 'non-random'),\n",
       " ('essentially', 'non-random', '.'),\n",
       " ('non-random',),\n",
       " ('non-random', '.'),\n",
       " ('non-random', '.', '</s>'),\n",
       " ('.',),\n",
       " ('.', '</s>'),\n",
       " ('.', '</s>', '</s>'),\n",
       " ('</s>',),\n",
       " ('</s>', '</s>'),\n",
       " ('</s>',)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(train_data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1212cd7d-7eb1-4a76-9868-e82f1914056b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'language',\n",
       " 'is',\n",
       " 'never',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'random',\n",
       " 'adam',\n",
       " 'kilgarriff',\n",
       " 'abstract',\n",
       " 'language',\n",
       " 'users',\n",
       " 'never',\n",
       " 'choose',\n",
       " 'words',\n",
       " 'randomly',\n",
       " ',',\n",
       " 'and',\n",
       " 'language',\n",
       " 'is',\n",
       " 'essentially',\n",
       " 'non-random',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'statistical',\n",
       " 'hypothesis',\n",
       " 'testing',\n",
       " 'uses',\n",
       " 'a',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " ',',\n",
       " 'which',\n",
       " 'posits',\n",
       " 'randomness',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'hence',\n",
       " ',',\n",
       " 'when',\n",
       " 'we',\n",
       " 'look',\n",
       " 'at',\n",
       " 'linguistic',\n",
       " 'phenomena',\n",
       " 'in',\n",
       " 'cor-',\n",
       " 'pora',\n",
       " ',',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " 'will',\n",
       " 'never',\n",
       " 'be',\n",
       " 'true',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'moreover',\n",
       " ',',\n",
       " 'where',\n",
       " 'there',\n",
       " 'is',\n",
       " 'enough',\n",
       " 'data',\n",
       " ',',\n",
       " 'we',\n",
       " 'shall',\n",
       " '(',\n",
       " 'almost',\n",
       " ')',\n",
       " 'always',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'establish',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'true',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'in',\n",
       " 'corpus',\n",
       " 'studies',\n",
       " ',',\n",
       " 'we',\n",
       " 'frequently',\n",
       " 'do',\n",
       " 'have',\n",
       " 'enough',\n",
       " 'data',\n",
       " ',',\n",
       " 'so',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'a',\n",
       " 'rela-',\n",
       " 'tion',\n",
       " 'between',\n",
       " 'two',\n",
       " 'phenomena',\n",
       " 'is',\n",
       " 'demonstrably',\n",
       " 'non-random',\n",
       " ',',\n",
       " 'does',\n",
       " 'not',\n",
       " 'sup-',\n",
       " 'port',\n",
       " 'the',\n",
       " 'inference',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'arbitrary',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'we',\n",
       " 'present',\n",
       " 'experimental',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'how',\n",
       " 'arbitrary',\n",
       " 'associations',\n",
       " 'between',\n",
       " 'word',\n",
       " 'frequencies',\n",
       " 'and',\n",
       " 'corpora',\n",
       " 'are',\n",
       " 'systematically',\n",
       " 'non-random',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'we',\n",
       " 'review',\n",
       " 'literature',\n",
       " 'in',\n",
       " 'which',\n",
       " 'hypothesis',\n",
       " 'test-',\n",
       " 'ing',\n",
       " 'has',\n",
       " 'been',\n",
       " 'used',\n",
       " ',',\n",
       " 'and',\n",
       " 'show',\n",
       " 'how',\n",
       " 'it',\n",
       " 'has',\n",
       " 'often',\n",
       " 'led',\n",
       " 'to',\n",
       " 'unhelpful',\n",
       " 'or',\n",
       " 'mislead-',\n",
       " 'ing',\n",
       " 'results',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'keywords',\n",
       " ':',\n",
       " '쎲쎲쎲',\n",
       " '1',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'introduction',\n",
       " 'any',\n",
       " 'two',\n",
       " 'phenomena',\n",
       " 'might',\n",
       " 'or',\n",
       " 'might',\n",
       " 'not',\n",
       " 'be',\n",
       " 'related',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'range',\n",
       " 'of',\n",
       " 'pos-',\n",
       " 'sibilities',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'association',\n",
       " 'is',\n",
       " 'random',\n",
       " ',',\n",
       " 'arbitrary',\n",
       " ',',\n",
       " 'motivated',\n",
       " 'or',\n",
       " 'pre-',\n",
       " 'dictable',\n",
       " '(',\n",
       " 'r',\n",
       " ',',\n",
       " 'a',\n",
       " ',',\n",
       " 'm',\n",
       " ',',\n",
       " 'p',\n",
       " ')',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'bulk',\n",
       " 'of',\n",
       " 'linguistic',\n",
       " 'questions',\n",
       " 'concern',\n",
       " 'the',\n",
       " 'dis-',\n",
       " 'tinction',\n",
       " 'between',\n",
       " 'a',\n",
       " 'and',\n",
       " 'm.',\n",
       " 'a',\n",
       " 'linguistic',\n",
       " 'account',\n",
       " 'of',\n",
       " 'a',\n",
       " 'phenomenon',\n",
       " 'gen-',\n",
       " 'erally',\n",
       " 'gives',\n",
       " 'us',\n",
       " 'reason',\n",
       " 'to',\n",
       " 'view',\n",
       " 'the',\n",
       " 'relation',\n",
       " 'between',\n",
       " ',',\n",
       " 'for',\n",
       " 'example',\n",
       " ',',\n",
       " 'a',\n",
       " 'verb',\n",
       " '’',\n",
       " 's',\n",
       " 'syntax',\n",
       " 'and',\n",
       " 'its',\n",
       " 'semantics',\n",
       " ',',\n",
       " 'as',\n",
       " 'motivated',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'arbitrary',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'however',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'in',\n",
       " 'general',\n",
       " 'possible',\n",
       " 'to',\n",
       " 'model',\n",
       " 'the',\n",
       " 'a-m',\n",
       " 'distinction',\n",
       " 'mathematically',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'distinction',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'modeled',\n",
       " 'mathematically',\n",
       " 'is',\n",
       " 'between',\n",
       " 'r',\n",
       " 'and',\n",
       " 'not-r',\n",
       " ',',\n",
       " 'that',\n",
       " 'is',\n",
       " ',',\n",
       " 'between',\n",
       " 'random',\n",
       " ',',\n",
       " 'or',\n",
       " 'uncorrelated',\n",
       " ',',\n",
       " 'pairs',\n",
       " 'and',\n",
       " 'pairs',\n",
       " 'where',\n",
       " 'there',\n",
       " 'is',\n",
       " 'some',\n",
       " 'correlation',\n",
       " ',',\n",
       " 'be',\n",
       " 'it',\n",
       " 'arbitrary',\n",
       " ',',\n",
       " 'motivated',\n",
       " 'or',\n",
       " 'predictable.1',\n",
       " 'the',\n",
       " 'mechanism',\n",
       " 'here',\n",
       " 'is',\n",
       " 'hypothesis-testing',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'a',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " ',',\n",
       " 'h0',\n",
       " 'is',\n",
       " 'con-',\n",
       " 'structed',\n",
       " 'to',\n",
       " 'model',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'in',\n",
       " 'which',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'correlation',\n",
       " 'between',\n",
       " 'corpus',\n",
       " 'linguistics',\n",
       " 'and',\n",
       " 'linguistic',\n",
       " 'theory',\n",
       " '1⫺2',\n",
       " '(',\n",
       " '2005',\n",
       " ')',\n",
       " ',',\n",
       " '263⫺275',\n",
       " '1613-7027/05/0001⫺0263',\n",
       " '쑕',\n",
       " 'walter',\n",
       " 'de',\n",
       " 'gruyter',\n",
       " '264',\n",
       " 'a.',\n",
       " 'kilgarriff',\n",
       " 'the',\n",
       " 'two',\n",
       " 'phenomena',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'as',\n",
       " 'the',\n",
       " 'mathematics',\n",
       " 'of',\n",
       " 'the',\n",
       " 'random',\n",
       " 'is',\n",
       " 'well',\n",
       " 'under-',\n",
       " 'stood',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'compute',\n",
       " 'the',\n",
       " 'likelihood',\n",
       " 'of',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " 'given',\n",
       " 'the',\n",
       " 'data',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'if',\n",
       " 'the',\n",
       " 'likelihood',\n",
       " 'is',\n",
       " 'low',\n",
       " ',',\n",
       " 'we',\n",
       " 'reject',\n",
       " 'h0',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'for',\n",
       " 'empirical',\n",
       " 'linguistics',\n",
       " 'is',\n",
       " 'that',\n",
       " 'language',\n",
       " 'is',\n",
       " 'not',\n",
       " 'random',\n",
       " ',',\n",
       " 'so',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " 'is',\n",
       " 'never',\n",
       " 'true',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'language',\n",
       " 'is',\n",
       " 'not',\n",
       " 'random',\n",
       " 'because',\n",
       " 'we',\n",
       " 'speak',\n",
       " 'or',\n",
       " 'write',\n",
       " 'with',\n",
       " 'purposes',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " ',',\n",
       " 'indeed',\n",
       " ',',\n",
       " 'without',\n",
       " 'computational',\n",
       " 'help',\n",
       " 'are',\n",
       " 'not',\n",
       " 'capable',\n",
       " 'of',\n",
       " ',',\n",
       " 'producing',\n",
       " 'words',\n",
       " 'or',\n",
       " 'sounds',\n",
       " 'or',\n",
       " 'sentences',\n",
       " 'or',\n",
       " 'documents',\n",
       " 'randomly',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " 'always',\n",
       " 'have',\n",
       " 'enough',\n",
       " 'data',\n",
       " 'to',\n",
       " 'reject',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " ',',\n",
       " 'but',\n",
       " 'that',\n",
       " 'is',\n",
       " 'a',\n",
       " 'distinct',\n",
       " 'issue',\n",
       " ':',\n",
       " 'wherever',\n",
       " 'there',\n",
       " 'is',\n",
       " 'enough',\n",
       " 'data',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'rejected',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'using',\n",
       " 'language',\n",
       " 'corpora',\n",
       " ',',\n",
       " 'we',\n",
       " 'are',\n",
       " 'frequently',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fortunate',\n",
       " 'position',\n",
       " 'of',\n",
       " 'having',\n",
       " 'very',\n",
       " 'large',\n",
       " 'quantities',\n",
       " 'of',\n",
       " 'data',\n",
       " 'at',\n",
       " 'our',\n",
       " 'disposal',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'then',\n",
       " ',',\n",
       " 'even',\n",
       " 'where',\n",
       " 'pairs',\n",
       " 'of',\n",
       " 'corpora',\n",
       " 'are',\n",
       " 'set',\n",
       " 'up',\n",
       " 'to',\n",
       " 'be',\n",
       " 'linguistically',\n",
       " 'identical',\n",
       " ',',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " 'is',\n",
       " 'resoundingly',\n",
       " 'defeated',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'in',\n",
       " 'section',\n",
       " '4',\n",
       " ',',\n",
       " 'we',\n",
       " 'present',\n",
       " 'an',\n",
       " 'experiment',\n",
       " 'demonstrating',\n",
       " 'this',\n",
       " 'counterintuitive',\n",
       " 'effect',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'there',\n",
       " 'are',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'papers',\n",
       " 'in',\n",
       " 'the',\n",
       " 'empirical',\n",
       " 'linguistics',\n",
       " 'literature',\n",
       " 'where',\n",
       " 'researchers',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'testing',\n",
       " 'whether',\n",
       " 'an',\n",
       " 'association',\n",
       " 'was',\n",
       " 'lin-',\n",
       " 'guistically',\n",
       " 'salient',\n",
       " ',',\n",
       " 'or',\n",
       " 'used',\n",
       " 'the',\n",
       " 'confidence',\n",
       " 'with',\n",
       " 'which',\n",
       " 'h0',\n",
       " 'could',\n",
       " 'be',\n",
       " 're-',\n",
       " 'jected',\n",
       " 'as',\n",
       " 'a',\n",
       " 'measure',\n",
       " 'of',\n",
       " 'salience',\n",
       " ',',\n",
       " 'whereas',\n",
       " 'in',\n",
       " 'fact',\n",
       " 'they',\n",
       " 'were',\n",
       " 'merely',\n",
       " 'testing',\n",
       " 'whether',\n",
       " 'they',\n",
       " 'had',\n",
       " 'enough',\n",
       " 'data',\n",
       " 'to',\n",
       " 'reject',\n",
       " 'h0',\n",
       " 'with',\n",
       " 'confidence',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'some',\n",
       " 'such',\n",
       " 'cases',\n",
       " 'are',\n",
       " 'reviewed',\n",
       " 'in',\n",
       " 'section',\n",
       " '5',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'hypothesis',\n",
       " 'testing',\n",
       " 'has',\n",
       " 'been',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'the',\n",
       " 'acquisition',\n",
       " 'of',\n",
       " 'subcategorization',\n",
       " 'frames',\n",
       " 'from',\n",
       " 'corpora',\n",
       " 'and',\n",
       " 'this',\n",
       " 'literature',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'in',\n",
       " 'some',\n",
       " 'detail',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'alternatives',\n",
       " 'to',\n",
       " 'inappropriate',\n",
       " 'hy-',\n",
       " 'pothesis-testing',\n",
       " 'are',\n",
       " 'presented',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'before',\n",
       " 'proceeding',\n",
       " ',',\n",
       " 'may',\n",
       " 'i',\n",
       " 'clarify',\n",
       " 'that',\n",
       " 'this',\n",
       " 'paper',\n",
       " 'is',\n",
       " 'in',\n",
       " 'no',\n",
       " 'way',\n",
       " 'critical',\n",
       " 'of',\n",
       " 'using',\n",
       " 'probability',\n",
       " 'models',\n",
       " ',',\n",
       " 'all',\n",
       " 'of',\n",
       " 'which',\n",
       " 'are',\n",
       " 'based',\n",
       " 'on',\n",
       " 'assumptions',\n",
       " 'of',\n",
       " 'randomness',\n",
       " ',',\n",
       " 'in',\n",
       " 'empirical',\n",
       " 'linguistics',\n",
       " 'in',\n",
       " 'general',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'probability',\n",
       " 'models',\n",
       " 'have',\n",
       " 'been',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'a',\n",
       " 'large',\n",
       " 'share',\n",
       " 'of',\n",
       " 'progress',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'in',\n",
       " 'the',\n",
       " 'last',\n",
       " 'decade',\n",
       " 'and',\n",
       " 'a',\n",
       " 'half',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'randomness',\n",
       " 'assumptions',\n",
       " 'are',\n",
       " 'always',\n",
       " 'untrue',\n",
       " ',',\n",
       " 'but',\n",
       " 'that',\n",
       " 'does',\n",
       " 'not',\n",
       " 'preclude',\n",
       " 'them',\n",
       " 'from',\n",
       " 'frequently',\n",
       " 'being',\n",
       " 'useful',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'making',\n",
       " 'false',\n",
       " 'assumptions',\n",
       " 'is',\n",
       " 'often',\n",
       " 'an',\n",
       " 'ingenious',\n",
       " 'way',\n",
       " 'to',\n",
       " 'proceed',\n",
       " ';',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'arises',\n",
       " 'where',\n",
       " 'the',\n",
       " 'literal',\n",
       " 'falsity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'assumption',\n",
       " 'is',\n",
       " 'overlooked',\n",
       " ',',\n",
       " 'and',\n",
       " 'inappropri-',\n",
       " 'ate',\n",
       " 'inferences',\n",
       " 'are',\n",
       " 'drawn',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " '2',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'arbitrary',\n",
       " 'and',\n",
       " 'the',\n",
       " 'random',\n",
       " 'in',\n",
       " 'common',\n",
       " 'parlance',\n",
       " ',',\n",
       " 'random',\n",
       " 'and',\n",
       " 'arbitrary',\n",
       " 'are',\n",
       " 'synonyms',\n",
       " ',',\n",
       " 'with',\n",
       " 'diction-',\n",
       " 'aries',\n",
       " 'giving',\n",
       " 'near-identical',\n",
       " 'definitions',\n",
       " ':',\n",
       " 'ldoce',\n",
       " '(',\n",
       " '1995',\n",
       " ')',\n",
       " 'defines',\n",
       " 'random',\n",
       " 'as',\n",
       " 'happening',\n",
       " 'or',\n",
       " 'chosen',\n",
       " 'without',\n",
       " 'any',\n",
       " 'definite',\n",
       " 'plan',\n",
       " ',',\n",
       " 'or',\n",
       " 'pattern',\n",
       " 'and',\n",
       " 'arbitrary',\n",
       " 'as',\n",
       " '1',\n",
       " 'decided',\n",
       " 'or',\n",
       " 'arranged',\n",
       " 'without',\n",
       " 'any',\n",
       " 'reason',\n",
       " 'or',\n",
       " 'plan',\n",
       " ',',\n",
       " 'often',\n",
       " 'unfairly',\n",
       " '…',\n",
       " '2',\n",
       " 'happening',\n",
       " 'or',\n",
       " 'decided',\n",
       " 'by',\n",
       " 'chance',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'a',\n",
       " 'plan',\n",
       " 'language',\n",
       " 'is',\n",
       " 'never',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'random',\n",
       " '265',\n",
       " 'superficially',\n",
       " ',',\n",
       " 'randomness',\n",
       " ',',\n",
       " 'as',\n",
       " 'defined',\n",
       " 'here',\n",
       " ',',\n",
       " 'is',\n",
       " 'what',\n",
       " 'the',\n",
       " 'technical',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'random',\n",
       " 'captures',\n",
       " 'and',\n",
       " 'makes',\n",
       " 'explicit',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'technical',\n",
       " 'sense',\n",
       " 'is',\n",
       " 'defined',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'statistical',\n",
       " 'independence',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'first',\n",
       " ',',\n",
       " 'we',\n",
       " 'formalize',\n",
       " 'the',\n",
       " 'framework',\n",
       " ':',\n",
       " 'for',\n",
       " 'a',\n",
       " 'population',\n",
       " 'of',\n",
       " 'events',\n",
       " ',',\n",
       " 'the',\n",
       " 'first',\n",
       " 'phenomenon',\n",
       " 'holds',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae06171e-b471-41fc-bb37-974fc3584141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE(Maximum Likelihood Estimation)\n",
    "from nltk.lm import MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f89e76d-4531-4361-8693-8b0e2a1c53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLE(3) # 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac336c3e-2dea-4270-9776-ff5d24cf7963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28b4c768-3fef-4438-a382-c323d564b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6512252b-65f7-4ba1-a83e-3bf617879ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.vocab)\n",
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "893b6e4b-50a3-4014-af0c-38ba1a724cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.score()\n",
    "model.score(\"is\", [\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f95b0402-967b-480a-af08-24d949ce1ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"never\", [\"language\", \"is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cf81785-b430-43cc-84a2-181a45fa6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = list(model.vocab)\n",
    "recommends = []\n",
    "for word in vocabs:\n",
    "    score = model.score(word, [\"language\", \"is\"])\n",
    "    if score >= 0.5:\n",
    "        recommends.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32df6f51-9b35-404f-af7f-e7374f9ea85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['never']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac27059-8cca-4f00-8988-3a2fb8d70086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.generate(토큰 갯수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f60c6354-7063-4321-a472-12a73b480b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['however',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'acquisition',\n",
       " 'of',\n",
       " 'subcategorization',\n",
       " 'frames',\n",
       " '(',\n",
       " 'scfs',\n",
       " ')',\n",
       " 'for',\n",
       " 'the',\n",
       " 'technical',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'random',\n",
       " 'captures']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fc3b8-d106-4cc4-97fa-5c3bbe5f106f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
